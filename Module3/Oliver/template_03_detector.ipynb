{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d36d77b",
   "metadata": {},
   "source": [
    "# Experimentation 3: Seizure Detection\n",
    "\n",
    "## Structure\n",
    "1. Data preparation (pre-processing)<br/>\n",
    "   Note: ideally you store the pre-processed data in template 02 and load it here again, instead of duplicating the code …\n",
    "2. Windowing\n",
    "3. Feature & label extraction\n",
    "4. Data split\n",
    "5. FV-pre-processing\n",
    "6. Classifier creation\n",
    "7. Evaluation\n",
    "\n",
    "\n",
    "## Reporting\n",
    "Not every plot or number generated in this template comes into the report.\n",
    "Nonetheless, some intermediary steps are required to achieve the relevant results.\n",
    "Cells, which have a *direct* relation to a part of the report, \n",
    "are marked with **Report:**.\n",
    "Be sure to not jump over relevant precursor steps.\n",
    "But when having little time, think about your priorities, and try to avoid spending time on decorative steps or cells which are not needed for the report.\n",
    "\n",
    "The relevant information about what to include in the report is the corresponding pdf document on itslearning.\n",
    "Annotations in this file are just for orientation and might not be complete.\n",
    "\n",
    "\n",
    "\n",
    "## What to do\n",
    "  - Build it up step by step, i.e\n",
    "      * First take a short look at how the pipeline looks like\n",
    "      * Initially, use the raw window as feature vector for starters to get everything going\n",
    "      * Implement the overlap of the window with the seizure,\n",
    "        so that you have a label\n",
    "      * Only then start implementing features\n",
    "      * Then, you can go on\n",
    "  - There are many parameters which influence the outcome\n",
    "      * Which influence does balancing have?\n",
    "      * How about scaling?\n",
    "      * And PCA with / without whitening?\n",
    "      * Try to get a feeling for how the PCA changes the channels, \n",
    "        i.e., plot consecutive channels on x/y axis.\n",
    "        Colour the dots according to their labels.\n",
    "      * How do your observations relate to your expectations?\n",
    "  - Investigate the relevance of features\n",
    "  - Without doing a proper evaluation, do you think that the relevance of the features correlates with the computaton time going into deriving them?\n",
    "  \n",
    "## Discussion\n",
    "In your group or with your neighbours\n",
    "- Which influence does the data preparation have? I.e., normalisation, PCA, whitening?\n",
    "- When comparing the use of PCA here to Module 2, how would you describe the interpretability of the dimensions?\n",
    "- Which performance do you achieve? Is the detector usable?\n",
    "- Reflecting on the performance of the detector, for which tasks would you trust this model? How would you like to change the performance for possible use cases?\n",
    "\n",
    "## When you are done with all other tasks…\n",
    "You can check template 3a for optional tasks to dig deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f26b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyedflib import highlevel\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Jupyter lab supports interactive plots      # Matplotlib for plotting\n",
    "# using \"widget\"\n",
    "%matplotlib widget\n",
    "\n",
    "# Jupyter lab doesn't support notebook,\n",
    "# which was the preferred method for jupyter notebooks.\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "# Adjust plot size & resolution for inline display.\n",
    "# Tune to your needs.\n",
    "plt.rcParams['figure.figsize'] = [9, 5.56]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f835c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining base paths for read-only and read-write data\n",
    "# will make it easy for us to switch between cloud\n",
    "# and local environments by just adjusting the paths.\n",
    "#\n",
    "# Also, it will prevent accidental overwriting of read-only data.\n",
    "#\n",
    "# The example codes starting with '/work' relate to UCloud.\n",
    "# Note that jupyterlab in ucloud will not show you the /work folder.\n",
    "# What jupyterlab shows as origin */* of the filesystem\n",
    "# is in reality the */work* folder.\n",
    "\n",
    "from pathlib import Path         # OS agnostic path handling (/ vs \\)\n",
    "\n",
    "user = 'jb'                      # Per-user output directories\n",
    "\n",
    "# Base directories\n",
    "# DATA_DIR -- where the read-only sources are\n",
    "DATA_DIR = Path('/work/data')\n",
    "\n",
    "# OUTPUT_DIR -- where we will keep our data (read/write)\n",
    "# We will make sure it exists!\n",
    "OUTPUT_DIR = Path('/work/output')\n",
    "\n",
    "# Now create our own output directory and change to it\n",
    "OUTPUT_DIR /= user\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import os\n",
    "os.chdir(OUTPUT_DIR)             # Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a903a",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "While this template replicates the boxes from template 02, it is advised to store the pre-processed data in template 02 and then load it again here, preventing you from duplicating all the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading file:\n",
    "fn = DATA_DIR / \\\n",
    "    'module_3_-_time_series_analysis_for_eeg' / \\\n",
    "    'seizure_eegs/' \\\n",
    "    '01.edf'\n",
    "\n",
    "print('Reading EEG from: {}'.format(fn))\n",
    "\n",
    "raw_signals, signal_headers, header = \\\n",
    "    highlevel.read_edf(str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotations:\n",
    "# In seconds since start of recording,\n",
    "# use singal_headers.sample_frequency to map to sample numbers\n",
    "seizures = list()\n",
    "for start, duration, kind in header['annotations']:\n",
    "    if kind == 'Seizure':\n",
    "        seizures.append((start, float(duration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f287c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier referencing of a specific channel:\n",
    "# A lookup table with the labels of all channels in the edf\n",
    "for i, sh in enumerate(signal_headers):\n",
    "    print('Channel {:2d}: {}'.format(i, sh['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35172d38",
   "metadata": {},
   "source": [
    "# Pre-Processing & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727e4ea",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Take from Task 2, or load pre-processed data from file.\n",
    "Note that you need to filter all channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REPLACE the following line of code!\n",
    "#       There is no need to keep it.\n",
    "signals = raw_signals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3567f",
   "metadata": {},
   "source": [
    "## Per-channel normalisation\n",
    "The signals have per definition a zero line.\n",
    "The easiest way to go on is therefore to scale symmetrically.\n",
    "Note though that this is a plump assumption and should be replaced by\n",
    "transforming to physical units first.\n",
    "\n",
    "Why do we normalise here?\n",
    "Well, we don't have to, but it is especially helpful for methods includig probability density function (pdf) estimation (Optional Tasks 3a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea52382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pass the values on to a new variable,\n",
    "# even if we by default do not filter the normalise\n",
    "# the signal here.\n",
    "norm_signals = None\n",
    "\n",
    "# Change to True to perform normalisation here.\n",
    "if False:\n",
    "    norm_signals = np.zeros((signals.shape[0] - 1, signals.shape[1]))\n",
    "    for i in range(signals.shape[0] - 1):\n",
    "        # Using variance should not be that sensitive to outliers as the maximum.\n",
    "        # But both perform good. For pdf estimation use max of absolute value.\n",
    "        #scaling_factor = 2 * np.sqrt(np.var(signals[i,:]))\n",
    "        scaling_factor = np.max(np.abs(signals[i,:]))\n",
    "        if scaling_factor == 0:\n",
    "            print('Channel #{} has no content!'.format(i))\n",
    "        norm_signals[i,:] = signals[i,:] / scaling_factor\n",
    "else:\n",
    "    norm_signals = signals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28904bd1",
   "metadata": {},
   "source": [
    "## Windowing function & overlap with seizure\n",
    "There are library functions which also do this.\n",
    "This implementaion is rather raw, but illustrates the idea.\n",
    "\n",
    "We analyse the time series in terms of windows. Given a signal + header,\n",
    "we can configure the window length + overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import windows\n",
    "    \n",
    "def interval_overlap(i1_start : float, i1_stop : float,\n",
    "            i2_start : float, i2_stop : float) -> float: \n",
    "    \n",
    "    \"\"\" A function to determine the overlap between intervals.\n",
    "\n",
    "        There are two options to implement this function.\n",
    "\n",
    "        (1) For starters, determine if there is an overlap.\n",
    "            If there is, then return 1\n",
    "\n",
    "        (2) Determine the actual overlap as a fraction in [0, 1],\n",
    "            return this value.\n",
    "    \n",
    "            Given the intervals [i1_start, i1_stop] and [i2_start, i2_stop],\n",
    "            return the overlap normalised to the smaller interval's length.\n",
    "    \n",
    "            This overlap will then be used determine how much of an interval\n",
    "            is seizure.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement the overlap between two intervals\n",
    "    pass\n",
    "\n",
    "\n",
    "def overlap_with_seizures(i1_start : float, i1_duration : float) -> float:\n",
    "    \"\"\" Determine the overlap of i1 with annotated seizures. \"\"\"\n",
    "\n",
    "    result : float = 0\n",
    "    for _start, _duration in seizures:\n",
    "        this = interval_overlap(i1_start, i1_start + i1_duration, _start, _start + _duration)\n",
    "        result += this\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def time_windows(signal, header, window_length_in_s, overlap_in_s):\n",
    "    \"\"\" Iterator over all time windows of a certain length.\n",
    "    \n",
    "        For a given signal, the return value of this function\n",
    "        can be iterated over to access all windows of specified\n",
    "        length and overlap.\n",
    "    \"\"\"\n",
    "    rate = header['sample_frequency']\n",
    "    window_length_in_samples = int(np.trunc(window_length_in_s * rate))\n",
    "    overlap_in_samples = int(np.trunc(overlap_in_s * rate))\n",
    "    step = window_length_in_samples - overlap_in_samples\n",
    "    \n",
    "    for i in range(0, len(signal), step):\n",
    "        if (len(signal) - i) < window_length_in_samples:\n",
    "            print('Information: incomplete window encountered. This is normal for the last window of a channel.')\n",
    "            return\n",
    "\n",
    "        yield (i + window_length_in_samples/2) / rate, \\\n",
    "              signal[i:i + window_length_in_samples], \\\n",
    "              overlap_with_seizures(i / rate, window_length_in_samples / rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88daec",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "For each window in each channel, we will generate a feature vector.\n",
    "The label will be determined by the overlap with the seizure annotation.\n",
    "\n",
    "General procedure:\n",
    " 1. Per-channel normalisation\n",
    " 2. Window splitting (time, signal, overlap of window with seizure annotation)\n",
    " 3. Calculation of features\n",
    " 4. Store: (time, features, label == overlap)\n",
    " \n",
    "I suggest to implement at least the following features\n",
    "  * mean\n",
    "  * variance\n",
    "  * energy\n",
    "  * area\n",
    "  * nonlinear_energy\n",
    "  * num_zero_crossings\n",
    "  * length_of_curve\n",
    "\n",
    "Please check with the lecture to get a detailed list of what is expected for a minimal implementation.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb20eaf",
   "metadata": {},
   "source": [
    "## Code for Calculating Features\n",
    "Of course, with more complex features, you are free to map this in the notebook structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature1(signal):\n",
    "    \"\"\" Calculate feature 1 on signal. \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def feature2(signal):\n",
    "    \"\"\" Calculate feature 2 on signal. \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c8be0",
   "metadata": {},
   "source": [
    "## Forming the Feature Vector\n",
    "Here, you actually plug in the features you want to include in the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_vector(sig):\n",
    "    \"\"\" Create a feature vector by combining all features. \"\"\"\n",
    "    return np.array([\n",
    "        feature1(sig),\n",
    "        feature2(sig),\n",
    "    ])\n",
    "\n",
    "# We derive the number of features automatically\n",
    "# by calling build_feature_vector with fake data.\n",
    "num_features = len(build_feature_vector(np.linspace(0, 19, 20)))\n",
    "print('Number of features per fv:', num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ba349",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "Now perform the feature calculations and collect the feature vectors for all windows.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per channel window splitting & feature vector creation\n",
    "# Optimisation options:\n",
    "#   * Save all windows, so that we can calculate features without window regeneration!\n",
    "#   * Extract windows for all channels at the same time\n",
    "window_length  = 3 # s\n",
    "window_overlap = 1 # s\n",
    "\n",
    "# For calculation of the number of windows\n",
    "window_length_in_samples = int(np.trunc(window_length * signal_headers[0]['sample_frequency']))\n",
    "overlap_in_samples = int(np.trunc(window_overlap * signal_headers[0]['sample_frequency']))\n",
    "\n",
    "num_channels = norm_signals.shape[0]\n",
    "num_windows = int(np.trunc(\n",
    "    (norm_signals.shape[1] - overlap_in_samples) / (window_length_in_samples - overlap_in_samples)\n",
    "))\n",
    "\n",
    "fv_times = np.zeros((num_windows))\n",
    "fvs = np.zeros((num_windows, num_channels * num_features))\n",
    "labels = np.zeros((num_windows))\n",
    "\n",
    "_window = None\n",
    "for ch_idx in range(norm_signals.shape[0]):\n",
    "    print('Extracting features for Channel #' + str(ch_idx), 'of', norm_signals.shape[0])\n",
    "    for win_idx, (start_time, win_data, overlap) in enumerate(time_windows(norm_signals[ch_idx], signal_headers[ch_idx], \n",
    "                                                                           window_length, window_overlap)):\n",
    "        fvs[win_idx, ch_idx * num_features:(ch_idx+1) * num_features] = build_feature_vector(win_data)\n",
    "        if (ch_idx == 0):\n",
    "            fv_times[win_idx] = start_time\n",
    "            labels[win_idx] = overlap\n",
    "        if (ch_idx == 0) and (win_idx == 0):\n",
    "            _window = win_data\n",
    "\n",
    "print(num_windows)\n",
    "print(num_channels, num_features, num_channels * num_features)\n",
    "print(fvs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdd37f",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Now comes the time to throw the feature vectors at different classifiers.\n",
    "But as we do not have the time to go into all the different options, we will stick to the logistic regression, which we know from Module 2 as a possible choice for classification tasks.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9659ccd",
   "metadata": {},
   "source": [
    "## Data Set Splitting\n",
    "While there are plenty of methods available to automate this part, we are here going to do it by hand, so that we can experiment with the process, i.e., you definitely want to fiddle with the balancing.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of data sets for training and evaluation\n",
    "balanced = False\n",
    "test_split = 0.8\n",
    "non_seizure_overhead = 1\n",
    "\n",
    "binary_labels : np.ndarray = labels > 0\n",
    "\n",
    "train_data : np.ndarray = None\n",
    "train_labels : np.ndarray = None\n",
    "test_data : np.ndarray = None\n",
    "test_labels : np.ndarray = None\n",
    "\n",
    "if balanced:      # Select seizures (lower number), and select interictal accordingly\n",
    "    from numpy.random import default_rng\n",
    "    rng = default_rng()\n",
    "\n",
    "    num_seizure_fvs = sum(binary_labels)\n",
    "    for_training = int(np.round(test_split * num_seizure_fvs))\n",
    "    print('Number of fvs with seizure:', num_seizure_fvs)\n",
    "    print('  Number of seizure training fvs:', for_training)\n",
    "    print('  Number of seizure validation fvs:', num_seizure_fvs - for_training)\n",
    "    print('  Number of interictal validation fvs:', \n",
    "          len(binary_labels) - num_seizure_fvs - non_seizure_overhead * for_training)\n",
    "    \n",
    "    # Get indices of ictal and interictal fvs.\n",
    "    # Should we shuffle them to make sure that we get a somewhat\n",
    "    # random selection? Might be bad, because this way, especially\n",
    "    # with the low numbers, we could end up only seeing beginnings…\n",
    "    seizure_idx = np.nonzero(binary_labels >= 0.5)[0]\n",
    "    interictal_idx = np.nonzero(binary_labels < 0.5)[0]\n",
    "    \n",
    "    # The classifier fit(…) will shuffle. But just in case we do so too.\n",
    "    training_idx = np.concatenate(\n",
    "        (seizure_idx[:for_training], interictal_idx[:non_seizure_overhead * for_training])\n",
    "    )\n",
    "    np.random.shuffle(training_idx)\n",
    "    test_idx = np.concatenate(\n",
    "        (seizure_idx[for_training:], interictal_idx[non_seizure_overhead * for_training:])\n",
    "    )\n",
    "    np.random.shuffle(test_idx)\n",
    "\n",
    "    _train_data = fvs[training_idx,:]\n",
    "    train_labels = binary_labels[training_idx]\n",
    "    _test_data = fvs[test_idx,:]\n",
    "    test_labels = binary_labels[test_idx]\n",
    "    \n",
    "else:             # Just split according to test_split\n",
    "    last = int(test_split * len(binary_labels))\n",
    "\n",
    "    _train_data = fvs[:last,:]\n",
    "    train_labels = binary_labels[:last]\n",
    "    _test_data = fvs[last:,:]\n",
    "    test_labels = binary_labels[last:]\n",
    "\n",
    "print('\\nData summary')\n",
    "print('  Number of feature vectors:', fvs.shape[0])\n",
    "print('  Size of training set:', _train_data.shape[0])\n",
    "print('  Size of validation set:', _test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b675fe",
   "metadata": {},
   "source": [
    "## Last Pre-Processing & PCA\n",
    "In this part, we investigate the improvements by using scaling and PCA for reducig dimensions and decorrelating signals.\n",
    "Please check [the scikit documentation on pre-processing](https://scikit-learn.org/stable/modules/preprocessing.html) for details on how the following settings are transforming the data.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ab0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "#\n",
    "# Scaling and PCA\n",
    "# Also check the order of PCA with/without whitening and scaling.\n",
    "\n",
    "do_PCA = True\n",
    "PCA_whiten = True\n",
    "PCA_n_comp = 'mle'\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class DummyScaler():\n",
    "    def fit(self, data):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data\n",
    "\n",
    "\n",
    "scaler = DummyScaler().fit(_train_data)\n",
    "#scaler = preprocessing.StandardScaler().fit(_train_data)\n",
    "#scaler = preprocessing.RobustScaler().fit(_train_data)\n",
    "\n",
    "train_data = scaler.transform(_train_data)\n",
    "test_data = scaler.transform(_test_data)\n",
    "\n",
    "print('Original dimensionality:', _train_data.shape[1])\n",
    "\n",
    "if do_PCA:\n",
    "    # Use PCA to reduce linear dependencies\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=PCA_n_comp, svd_solver='full', whiten=PCA_whiten, copy=True)\n",
    "    pca.fit(train_data)\n",
    "    train_data = pca.transform(train_data)\n",
    "    test_data = pca.transform(test_data)\n",
    "\n",
    "    print('PCA performed. # reduced dimensions:', pca.n_components_)\n",
    "    print('   Ratio of variance explained:', pca.explained_variance_ratio_[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c193fb",
   "metadata": {},
   "source": [
    "## Optional: Inspecting the PCA's Effect\n",
    "For trying to get a feeling for how the PCA changes the channels, please plot consecutive or two otherwise selected channels on x/y axis.\n",
    "Colour the dots according to their labels.\n",
    "\n",
    "Can you find dimensions which separate the labels better than others?\n",
    "Keep them in mind when checking later the relevance of the features.\n",
    "\n",
    "This part is for trying to get a feeling of how the PCA might help the classifier,\n",
    "it is an explorative task, which means trying out, plotting, and inspecting.\n",
    "Do this only after you have completed your report, to avoid getting stuck here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ed7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "877f6408",
   "metadata": {},
   "source": [
    "# Create a Model\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adba26",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate accuracy, sensitivity, specificity, confusion matrix.\n",
    "What do these measures tell us about the performance of our model?\n",
    "\n",
    "Check which features were most relevant.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1da85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
