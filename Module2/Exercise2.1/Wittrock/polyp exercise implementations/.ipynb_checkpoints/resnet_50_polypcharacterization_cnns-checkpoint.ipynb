{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb4754d-5e52-44e9-ab38-d7b720c97b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (80.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a879d0d3-058f-4e7c-9a74-778e4e721852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './PCData/Non-neoplasia'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     42\u001b[39m neoplastic_folder = \u001b[33m'\u001b[39m\u001b[33m./PCData/Neoplasia\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     43\u001b[39m nonneoplastic_folder = \u001b[33m'\u001b[39m\u001b[33m./PCData/Non-neoplasia\u001b[39m\u001b[33m'\u001b[39m  \n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m nonneoplastic_data = [(os.path.join(nonneoplastic_folder, file), \u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnonneoplastic_folder\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file.startswith(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m     47\u001b[39m neoplastic_data = [(os.path.join(neoplastic_folder, file), \u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os.listdir(neoplastic_folder) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file.startswith(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m     48\u001b[39m data = neoplastic_data + nonneoplastic_data\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './PCData/Non-neoplasia'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Aug  1 19:42:57 2024\n",
    "\n",
    "@author: vigo\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import PIL\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet50, densenet121, efficientnet_b0\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Hyper-parameters \n",
    "batch_size = 32\n",
    "n_epochs = 20\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "# Specify the root folders for neoplastic and nonneoplastic images\n",
    "neoplastic_folder = './PCData/Neoplasia'\n",
    "nonneoplastic_folder = './PCData/Non-neoplasia'  \n",
    "\n",
    "\n",
    "nonneoplastic_data = [(os.path.join(nonneoplastic_folder, file), 0) for file in os.listdir(nonneoplastic_folder) if not file.startswith('.')]\n",
    "neoplastic_data = [(os.path.join(neoplastic_folder, file), 1) for file in os.listdir(neoplastic_folder) if not file.startswith('.')]\n",
    "data = neoplastic_data + nonneoplastic_data\n",
    "\n",
    "# Create the train dataset using train_data.txt\n",
    "train_data = []\n",
    "train_ids = set()  # Define train_ids before adding elements to it\n",
    "# Assuming train_data.txt contains data in the format: id \\t ccenum \\t class_type\n",
    "with open('train_data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Assuming train_data.txt contains data in the format: id \\t ccenum \\t class_type\n",
    "        sdkid = line.strip().split(',')[0]\n",
    "        train_ids.add(sdkid)\n",
    "\n",
    "\n",
    "# Iterate through your neoplastic and nonneoplastic data\n",
    "for filepath, label in data:\n",
    "    filename = os.path.basename(filepath)\n",
    "    sdkid_train = filename.split('_')[0]  # Assuming sdkid is the prefix before '_'\n",
    "    #print(sdkid_data)\n",
    "    if sdkid_train in train_ids:\n",
    "        train_data.append((filepath, label))\n",
    "\n",
    "\n",
    "\n",
    "# Create the valid dataset using valid_data.txt\n",
    "valid_data = []\n",
    "valid_ids = set()  # Define train_ids before adding elements to it\n",
    "# Assuming train_data.txt contains data in the format: id \\t ccenum \\t class_type\n",
    "with open('valid_data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Assuming train_data.txt contains data in the format: id \\t ccenum \\t class_type\n",
    "        sdkid = line.strip().split(',')[0]\n",
    "        valid_ids.add(sdkid)\n",
    "\n",
    "# Iterate through your neoplastic and nonneoplastic data\n",
    "for filepath, label in data:\n",
    "    filename = os.path.basename(filepath)\n",
    "    sdkid_val = filename.split('_')[0]  # Assuming sdkid is the prefix before '_'\n",
    "    #print(sdkid_data)\n",
    "    if sdkid_val in valid_ids:\n",
    "        valid_data.append((filepath, label))\n",
    "              \n",
    "# Create the test dataset using train_data.txt\n",
    "test_data = []\n",
    "test_ids = set()  # Define train_ids before adding elements to it\n",
    "# Assuming train_data.txt contains data in the format: id \\t ccenum \\t class_type\n",
    "with open('test_data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Assuming train_data.txt contains data in the format: id \\t ccenum \\t class_type\n",
    "        sdkid = line.strip().split(',')[0]\n",
    "        test_ids.add(sdkid)\n",
    "\n",
    "# Iterate through your neoplastic and nonneoplastic data\n",
    "for filepath, label in data:\n",
    "    filename = os.path.basename(filepath)\n",
    "    sdkid_test = filename.split('_')[0]  # Assuming sdkid is the prefix before '_'\n",
    "    #print(sdkid_data)\n",
    "    if sdkid_test in test_ids:\n",
    "        test_data.append((filepath, label))\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, os.path.basename(img_path)\n",
    "    \n",
    "    \n",
    "\n",
    "# Define a variety of augmentations without resizing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    #transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    #transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize images \n",
    "])\n",
    "\n",
    "# Create the custom dataset instances for training, validation, and testing\n",
    "train_dataset = CustomDataset(data=train_data, transform=transform)\n",
    "valid_dataset = CustomDataset(data=valid_data, transform=transform)\n",
    "test_dataset = CustomDataset(data=test_data, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoader for training, validation, and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5e5dd-83e5-4a33-80af-455bfb61e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(img):\n",
    "    img = img * 0.5 + 0.5  # reverse normalization\n",
    "    return img\n",
    "\n",
    "# select 16 random indices for plotting\n",
    "indices = random.sample(range(len(train_dataset)), 16)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    image, label, image_name = train_dataset[idx]\n",
    "\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.numpy()\n",
    "\n",
    "    if image.shape[0] == 3:  # RGB\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        image = unnormalize(image)\n",
    "    elif image.shape[0] == 1:  # Grayscale\n",
    "        image = image.squeeze(0)\n",
    "        image = unnormalize(image)\n",
    "\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image, cmap='gray' if image.ndim == 2 else None)\n",
    "    plt.title(f\"Label: {label}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41153e-15a7-4cf3-913b-1dfb8f81460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, criterion, optimizer\n",
    "pc_model = resnet50(pretrained=True).to(device)  # Single output for binary classification\n",
    "pc_model.fc = nn.Linear(pc_model.fc.in_features, 1)\n",
    "pc_model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(pc_model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155ed00-660d-4b49-8e4a-fd47d1b2fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    n_total_steps = len(dataloader.sampler)\n",
    "    for images, targets, image_names in dataloader:\n",
    "        images, targets = images.to(device), targets.to(device).float().view(-1, 1) \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predictions = (torch.sigmoid(outputs) > 0.65).float()\n",
    "        train_correct += (predictions == targets).sum().item()\n",
    "            \n",
    "    # Calculate training accuracy\n",
    "    train_acc = train_correct / n_total_steps * 100\n",
    "    return train_acc\n",
    "\n",
    "def val(model, device, dataloader, criterion):\n",
    "    n_total_samples = 0\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_names in dataloader:\n",
    "            images, targets = images.to(device), targets.to(device).float().view(-1, 1) \n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            predictions = (torch.sigmoid(outputs) > 0.65).float()\n",
    "            val_correct += (predictions == targets).sum().item()\n",
    "            n_total_samples += targets.size(0)\n",
    "        \n",
    "    val_acc = val_correct / n_total_samples * 100\n",
    "    avg_val_loss = val_loss / len(dataloader)\n",
    "    return avg_val_loss, val_acc\n",
    "\n",
    "\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    train_acc = train(pc_model, device, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = val(pc_model, device, val_loader, criterion)\n",
    "    print(f'Epoch [{e+1}/{n_epochs}], Train Accuracy: {train_acc:.2f}%, Val Accuracy: {val_acc:.2f}%, Val Loss: {val_loss:.4f}')\n",
    "       \n",
    "\n",
    "test_loss, test_acc = val(pc_model, device, test_loader, criterion)\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30e0d6-dde1-4f52-bf88-b592239d11b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
